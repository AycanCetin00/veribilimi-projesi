import pandas as pd
import ast
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import numpy as np
from sklearn.decomposition import PCA
import joblib
from sklearn.metrics.pairwise import euclidean_distances
from sklearn.metrics import silhouette_score

# TÃ¼rkÃ§e yazÄ± desteÄŸi
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'DejaVu Sans']

# -------------------------------------------
# 1) VERÄ°YÄ° OKUMA VE RASTGELE Ã–RNEKLEME
# -------------------------------------------

# TÃ¼m veriyi oku
movies_full = pd.read_csv("movies.csv")
credits = pd.read_csv("credits.csv")

print(f"ğŸ“½ï¸  Orijinal film veri seti: {len(movies_full)} film")

# Rastgele 1000 film seÃ§ (her Ã§alÄ±ÅŸtÄ±rmada farklÄ± olacak)
np.random.seed(None)
sample_size = min(1000, len(movies_full))
movies = movies_full.sample(n=sample_size, random_state=None).reset_index(drop=True)

print(f"âœ… SeÃ§ilen rastgele Ã¶rneklem: {len(movies)} film")
print("\nğŸ“‹ Film veri seti (ilk 5 film):")
print(movies.head())

# -------------------------------------------
# 2) GEREKSÄ°Z SÃœTUNLARI SÄ°LME
# -------------------------------------------
movies_clean = movies.drop(columns=[
    "homepage",
    "tagline",
    "spoken_languages",
    "keywords",
    "production_companies",
    "production_countries",
    "original_title",
    "overview"
])

print("\nâœ‚ï¸  Temizleme iÅŸlemi tamamlandÄ±")
print(f"Kalan sÃ¼tunlar: {movies_clean.columns.tolist()}")
print(f"Veri seti boyutu: {movies_clean.shape[0]} satÄ±r Ã— {movies_clean.shape[1]} sÃ¼tun")

# -------------------------------------------
# 3) EKSÄ°K VERÄ°LERÄ° DOLDURMA
# -------------------------------------------

# runtime (film sÃ¼resi) eksiklerini medyan ile doldur
movies_clean["runtime"] = movies_clean["runtime"].fillna(movies_clean["runtime"].median())

# release_date (Ã§Ä±kÄ±ÅŸ tarihi) eksik olan satÄ±rlarÄ± sil
movies_clean = movies_clean.dropna(subset=["release_date"])

print("\nğŸ”§ Eksik verileri tamamlandÄ±:")
print(movies_clean.isnull().sum())

# -------------------------------------------
# 4) TARÄ°HÄ° (release_date) YIL FORMATINA Ã‡EVÄ°RME
# -------------------------------------------
movies_clean["release_date"] = pd.to_datetime(movies_clean["release_date"], errors="coerce")
movies_clean["release_year"] = movies_clean["release_date"].dt.year

print("\nğŸ“… Tarih â†’ YÄ±l dÃ¶nÃ¼ÅŸÃ¼mÃ¼ Ã¶rnek:")
print(movies_clean[["release_date", "release_year"]].head())

# -------------------------------------------
# 5) GENRE (TÃœR) SÃœTUNUNU DÃœZENLEME
# -------------------------------------------
def extract_genres(g):
    """TÃ¼rleri string'den liste'ye Ã§evir"""
    try:
        g = ast.literal_eval(g)
        return [genre["name"] for genre in g]
    except:
        return []

movies_clean["genre_list"] = movies_clean["genres"].apply(extract_genres)

print("\nğŸ¬ Film tÃ¼rleri (Ã–rnek):")
print(movies_clean[["title", "genre_list"]].head())

# -------------------------------------------
# 6) GÃ–RSELLEÅTÄ°RME
# -------------------------------------------

# ğŸ“Š TÃœRLERE GÃ–RE FÄ°LM SAYISI
all_genres = movies_clean["genre_list"].explode()
genre_counts = all_genres.value_counts()

plt.figure(figsize=(12,6))
genre_counts.plot(kind="bar", color="steelblue")
plt.title("ğŸ“Š Film TÃ¼rlerinin DaÄŸÄ±lÄ±mÄ± (Toplam 1000 filmde hangi tÃ¼rler en yaygÄ±n?)", fontsize=14, fontweight='bold')
plt.xlabel("Film TÃ¼rleri")
plt.ylabel("Film SayÄ±sÄ±")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# ğŸ“ˆ OY SAYISININ DAÄILIMI
plt.figure(figsize=(10,5))
plt.hist(movies_clean["vote_count"], bins=40, color="lightcoral", edgecolor='black')
plt.title("ğŸ“ˆ Filmlerin AldÄ±ÄŸÄ± Oy SayÄ±sÄ± DaÄŸÄ±lÄ±mÄ±\n(KaÃ§ kiÅŸi filme oy vermiÅŸ?)", fontsize=14, fontweight='bold')
plt.xlabel("Oy SayÄ±sÄ±")
plt.ylabel("Film FrekansÄ± (kaÃ§ film bu kadar oy aldÄ±?)")
plt.grid(axis='y', alpha=0.3)
plt.show()

# ğŸ’° POPÃœLARÄ°TE vs GELÄ°R Ä°LÄ°ÅKÄ°SÄ°
plt.figure(figsize=(10,6))
plt.scatter(movies_clean["popularity"], movies_clean["revenue"], alpha=0.5, s=50, color="darkgreen")
plt.title("ğŸ’° Film PopÃ¼laritesi vs GiÅŸe Geliri\n(PopÃ¼ler filmler daha fazla gelir mi?)", fontsize=14, fontweight='bold')
plt.xlabel("PopÃ¼larite PuanÄ± (0-100)")
plt.ylabel("GiÅŸe Geliri ($)")
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# ğŸ”— SAYISAL Ã–ZELLÄ°KLER ARASINDA Ä°LÄ°ÅKÄ°
numeric_cols = movies_clean[["budget", "popularity", "revenue", "runtime", "vote_average", "vote_count"]]

plt.figure(figsize=(10,8))
sns.heatmap(numeric_cols.corr(), annot=True, cmap="coolwarm", cbar_kws={'label': 'Korelasyon'})
plt.title("ğŸ”— SayÄ±sal Ã–zellikler ArasÄ±ndaki Ä°liÅŸkiler\n(Renkler ne kadar kuvvetli iliÅŸki olduÄŸunu gÃ¶sterir)", fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

# -------------------------------------------
# 7) KÃœMELEME MODELÄ° (K-MEANS) - FÄ°LMLERÄ° GRUPLAMA
# -------------------------------------------

print("\n" + "="*100)
print("ğŸ¯ ADIM 3: KÃœMELEMEYÄ° (FÄ°LMLERÄ° GRUPLAMA) BAÅLATIYORUZ")
print("="*100)

# KullanÄ±lacak Ã¶zellikleri seÃ§
feature_cols = ["budget", "popularity", "revenue", "runtime", "vote_average", "vote_count"]

print(f"\nğŸ“ SeÃ§ilen Ã¶zellikler:")
for i, col in enumerate(feature_cols, 1):
    print(f"   {i}. {col}")

# Kopyala ve sayÄ±sal yap
clustering_df = movies_clean[feature_cols].copy()
for c in feature_cols:
    clustering_df[c] = pd.to_numeric(clustering_df[c], errors="coerce")

# Eksikleri kaldÄ±r
clustering_df = clustering_df.dropna()
valid_idx = clustering_df.index

print(f"\nâœ… KÃ¼meleme iÃ§in hazÄ±r film sayÄ±sÄ±: {len(clustering_df)} film")

# Verileri normalize et (0-1 arasÄ±na Ã§evir)
scaler = StandardScaler()
scaled = scaler.fit_transform(clustering_df)

# En uygun kÃ¼me sayÄ±sÄ±nÄ± bul (1 ile 10 arasÄ±nda test et)
inertias = []
sil_scores = []
K_range = range(1, 11)

print("\nğŸ” En uygun kÃ¼me sayÄ±sÄ±nÄ± arÄ±yor...")
for k in K_range:
    km = KMeans(n_clusters=k, random_state=42, n_init=10)
    km.fit(scaled)
    inertias.append(km.inertia_)
    if k >= 2:
        sil_scores.append(silhouette_score(scaled, km.labels_))
    else:
        sil_scores.append(np.nan)

# Grafikleri gÃ¶ster
plt.figure(figsize=(14,5))

# Elbow yÃ¶ntemi
plt.subplot(1,2,1)
plt.plot(K_range, inertias, "bo-", linewidth=2, markersize=8)
plt.title("ğŸ“‰ Elbow YÃ¶ntemi\n(En uygun kÃ¼me sayÄ±sÄ±nÄ± bulmak iÃ§in)", fontsize=12, fontweight='bold')
plt.xlabel("KÃ¼me SayÄ±sÄ± (k)")
plt.ylabel("Ä°Ã§ Hata (Inertia - DÃ¼ÅŸÃ¼k olmasÄ± iyi)")
plt.grid(True, alpha=0.3)
for i, k in enumerate(K_range):
    plt.text(k, inertias[i], f'{inertia:.0f}', ha='center', fontsize=8)

# Silhouette skoru
plt.subplot(1,2,2)
valid_sil = [(k, score) for k, score in zip(K_range, sil_scores) if not np.isnan(score)]
k_vals = [v[0] for v in valid_sil]
s_vals = [v[1] for v in valid_sil]
plt.plot(k_vals, s_vals, "go-", linewidth=2, markersize=8)
plt.title("â­ Silhouette Skoru\n(YÃ¼ksek olmasÄ± iyi kÃ¼melenme anlamÄ±na gelir)", fontsize=12, fontweight='bold')
plt.xlabel("KÃ¼me SayÄ±sÄ± (k)")
plt.ylabel("Silhouette Skoru (0 ile 1 arasÄ±nda)")
plt.grid(True, alpha=0.3)
for k, score in valid_sil:
    plt.text(k, score, f'{score:.2f}', ha='center', fontsize=8)

plt.tight_layout()
plt.show()

# Otomatik seÃ§im
best_k = int(np.nanargmax(sil_scores) + 1)
if best_k < 2:
    best_k = 3

print(f"\nâœ¨ En iyi kÃ¼me sayÄ±sÄ± seÃ§ildi: k = {best_k}")

# Final kÃ¼meleme
kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)
labels = kmeans.fit_predict(scaled)

movies_clean.loc[valid_idx, "cluster"] = labels

print(f"\nâœ… KÃ¼meleme tamamlandÄ±!")
print(f"ğŸï¸  Her kÃ¼mede kaÃ§ film var?")
print(movies_clean["cluster"].value_counts().sort_index())

# KÃ¼me merkezlerini gÃ¶ster
centers_df = pd.DataFrame(
    scaler.inverse_transform(kmeans.cluster_centers_),
    columns=feature_cols
)
print(f"\nğŸ“Š KÃ¼melerin Ã–zellikleri (Merkez DeÄŸerler):")
print(centers_df.round(2))

# Her kÃ¼mede Ã¶rnek filmler
print(f"\nğŸ¬ Her KÃ¼meden Ã–rnek Filmler:")
for cl in sorted(movies_clean["cluster"].dropna().unique()):
    print(f"\n--- GRUP {int(cl)} (TOPLAM {len(movies_clean[movies_clean['cluster']==cl])} FÄ°LM) ---")
    print("PopÃ¼ler filmler:")
    print(movies_clean[movies_clean["cluster"]==cl]
          .nlargest(3, 'popularity')[["title","release_year","budget","popularity"]]
          .to_string(index=False))

# -------------------------
# 8) KÃœMELERI GÃ–RSEL OLARAK GÃ–STER (2 Boyutlu)
# -------------------------

pca = PCA(n_components=2, random_state=42)
proj = pca.fit_transform(scaled)
proj_df = pd.DataFrame(proj, index=valid_idx, columns=["Boyut 1", "Boyut 2"])
proj_df["KÃ¼me"] = labels

plt.figure(figsize=(10,7))
colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']
for cluster in sorted(proj_df["KÃ¼me"].unique()):
    mask = proj_df["KÃ¼me"] == cluster
    plt.scatter(proj_df[mask]["Boyut 1"], 
               proj_df[mask]["Boyut 2"],
               label=f'Grup {int(cluster)}',
               s=100,
               alpha=0.7,
               color=colors[int(cluster) % len(colors)])

plt.title("ğŸï¸  Filmler KÃ¼melere GÃ¶re GruplandÄ±rÄ±ldÄ±\n(Her renk farklÄ± bir film grubunu temsil eder)", 
         fontsize=14, fontweight='bold')
plt.xlabel("Boyut 1 (Temel Ã–zellik)")
plt.ylabel("Boyut 2 (Ä°kincil Ã–zellik)")
plt.legend(loc='best', fontsize=10)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# -------------------------
# 9) KÃœMELERIN Ã–ZELLÄ°KLERÄ°
# -------------------------

profile = clustering_df.copy()
profile["KÃ¼me"] = labels

print("\n" + "="*100)
print("ğŸ“Š HER KÃœMENIN ORTALAMA Ã–ZELLÄ°KLERÄ°")
print("="*100)
print(profile.groupby("KÃ¼me").mean().round(2))

# TÃ¼r daÄŸÄ±lÄ±mÄ±
movies_with_clusters = movies_clean.loc[valid_idx].copy()
movies_with_clusters["KÃ¼me"] = labels
movies_with_clusters["genre_list"] = movies_with_clusters["genre_list"].apply(lambda g: g if isinstance(g, list) else [])
genre_by_cluster = (movies_with_clusters.explode("genre_list")
                    .groupby(["KÃ¼me","genre_list"])["title"].count()
                    .reset_index(name="Film SayÄ±sÄ±"))

print("\n" + "="*100)
print("ğŸ¬ HER KÃœMEDEKI EN YAYGIN TÃœRLER")
print("="*100)
for cl in sorted(movies_with_clusters["KÃ¼me"].unique()):
    print(f"\n--- GRUP {int(cl)} ---")
    cluster_genres = genre_by_cluster[genre_by_cluster["KÃ¼me"] == cl].nlargest(5, "Film SayÄ±sÄ±")
    for idx, (_, row) in enumerate(cluster_genres.iterrows(), 1):
        print(f"   {idx}. {row['genre_list']}: {int(row['Film SayÄ±sÄ±'])} film")

# -------------------------
# 10) KÃœMELEME MODELÄ°NÄ° KAYDETME
# -------------------------
joblib.dump({"scaler": scaler, "kmeans": kmeans, "pca": pca}, "kmeans_pipeline.joblib")
print("\nâœ… Model kaydedildi: kmeans_pipeline.joblib")

# -------------------------
# 11) BASÄ°T Ã–NERÄ° FONKSÄ°YONU
# -------------------------

def recommend_similar_titles(title, top_n=5):
    """AynÄ± gruptaki benzer filmleri Ã¶ner"""
    if title not in movies_with_clusters["title"].values:
        print(f"âŒ Film '{title}' bulunamadÄ±!")
        return pd.DataFrame()
    
    idx = movies_with_clusters[movies_with_clusters["title"]==title].index[0]
    if idx not in valid_idx:
        return pd.DataFrame()
    
    cl = movies_with_clusters.loc[idx, "KÃ¼me"]
    cand_idx = movies_with_clusters[movies_with_clusters["KÃ¼me"]==cl].index
    feat_matrix = scaled[np.isin(valid_idx, cand_idx)]
    target_vec = scaled[list(valid_idx).index(idx)]
    dists = euclidean_distances([target_vec], feat_matrix)[0]
    ranked = pd.DataFrame({"idx": cand_idx, "dist": dists}).sort_values("dist")
    ranked = ranked[ranked["idx"] != idx].head(top_n)
    return movies_with_clusters.loc[ranked["idx"], ["title","release_year","popularity","KÃ¼me"]]

print("\n" + "="*100)
print("ğŸ’¡ Ã–RNEK: BÄ°R FÄ°LME BENZER FÄ°LMLER Ã–NERME")
print("="*100)
sample_title = movies_with_clusters["title"].iloc[0]
print(f"\nğŸ¬ SeÃ§ilen film: {sample_title}")
print("\nğŸ“½ï¸  AynÄ± gruptaki benzer filmler:")
print(recommend_similar_titles(sample_title, top_n=5))

# -------------------------
# 12) KULLANICI VERÄ°SÄ° OLUÅTURMA (SÄ°MÃœLASYON)
# -------------------------

print("\n" + "="*100)
print("ğŸ‘¥ ADIM 4: KURGUSAL KULLANICI VERÄ°SÄ° OLUÅTURULUYOR")
print("="*100)

np.random.seed(None)
n_users = 100
n_watches_per_user = (5, 20)

user_watch_data = []
for user_id in range(1, n_users + 1):
    n_watches = np.random.randint(n_watches_per_user[0], n_watches_per_user[1])
    movie_ids = np.random.choice(
        movies_with_clusters["id"].dropna().values, 
        min(n_watches, len(movies_with_clusters)), 
        replace=False
    )
    for movie_id in movie_ids:
        user_watch_data.append({
            'user_id': user_id,
            'movie_id': int(movie_id),
            'rating': np.random.uniform(3, 10)
        })

user_behavior_df = pd.DataFrame(user_watch_data)
print(f"\nâœ… KullanÄ±cÄ± verileri hazÄ±r!")
print(f"ğŸ‘¥ Toplam KullanÄ±cÄ±: {user_behavior_df['user_id'].nunique()}")
print(f"ğŸ¬ Toplam Ä°zleme KaydÄ±: {len(user_behavior_df)}")
print(f"ğŸ“Š Ortalama her kullanÄ±cÄ± {len(user_behavior_df)/user_behavior_df['user_id'].nunique():.1f} film izlemiÅŸ")

# -------------------------
# 13) KULLANICI-FÄ°LM TABLOSU OLUÅTUR
# -------------------------

user_item_matrix = user_behavior_df.pivot_table(
    index='user_id',
    columns='movie_id',
    values='rating',
    fill_value=0
)

print(f"\nğŸ“Š KullanÄ±cÄ±-Film Tablosu: {user_item_matrix.shape[0]} kullanÄ±cÄ± Ã— {user_item_matrix.shape[1]} film")

# -------------------------
# 14) Ä°ÅBÄ°RLÄ°KÃ‡Ä° FÄ°LTRELEME (Benzer KullanÄ±cÄ± Bulma)
# -------------------------

def find_similar_users(user_id, top_n=5):
    """Benzer zevkleri olan kullanÄ±cÄ±larÄ± bul"""
    if user_id not in user_item_matrix.index:
        return []
    
    user_vector = user_item_matrix.loc[user_id]
    similarities = user_item_matrix.corrwith(user_vector, axis=1)
    similarities = similarities.drop(index=user_id, errors="ignore")
    similar_users = similarities[similarities > 0].sort_values(ascending=False).head(top_n)
    return similar_users.index.tolist()

def recommend_movies_collaborative(user_id, top_n=5):
    """Ä°ÅŸbirlikÃ§i Filtreleme: Benzer kullanÄ±cÄ±larÄ±n izledikleri filmleri Ã¶ner"""
    if user_id not in user_item_matrix.index:
        return pd.DataFrame()
    
    similar_users = find_similar_users(user_id, top_n=10)
    
    if not similar_users:
        return pd.DataFrame()
    
    recommendations = user_item_matrix.loc[similar_users].sum(axis=0)
    user_watched = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id] > 0].index
    recommendations = recommendations[~recommendations.index.isin(user_watched)]
    
    top_movie_ids = recommendations.nlargest(top_n).index.tolist()
    result = movies_with_clusters[movies_with_clusters['id'].isin(top_movie_ids)][
        ['id', 'title', 'release_year', 'popularity', 'KÃ¼me']
    ]
    return result

# -------------------------
# 15) Ä°Ã‡ERÄ°K TABANLI Ã–NERI (Benzer TÃ¼r Bulma)
# -------------------------

def recommend_movies_content_based(user_id, top_n=5):
    """Ä°Ã§erik TabanlÄ±: KullanÄ±cÄ±nÄ±n izlediÄŸi tÃ¼rdeki diÄŸer filmleri Ã¶ner"""
    user_movies = user_behavior_df[user_behavior_df['user_id'] == user_id]['movie_id'].values
    user_genres = set()
    
    for movie_id in user_movies:
        genres = movies_with_clusters[movies_with_clusters['id'] == movie_id]['genre_list'].values
        if len(genres) > 0:
            user_genres.update(genres[0])
    
    if not user_genres:
        return pd.DataFrame()
    
    candidates = movies_with_clusters[
        movies_with_clusters['genre_list'].apply(lambda x: bool(user_genres & set(x)))
    ]
    
    candidates = candidates[~candidates['id'].isin(user_movies)]
    result = candidates.nlargest(top_n, 'popularity')[
        ['id', 'title', 'release_year', 'popularity', 'genre_list', 'KÃ¼me']
    ]
    return result

# -------------------------
# 16) HÄ°BRÄ°T Ã–NERI (2 YÃ¶ntemi BirleÅŸtir)
# -------------------------

def recommend_movies_hybrid(user_id, top_n=5, alpha=0.6):
    """Hibrit: Ä°ÅŸbirlikÃ§i ve Ä°Ã§erik TabanlÄ± Ã–nerileri BirleÅŸtir"""
    collab_recs = recommend_movies_collaborative(user_id, top_n=top_n*2)
    content_recs = recommend_movies_content_based(user_id, top_n=top_n*2)
    
    hybrid_scores = {}
    
    for _, row in collab_recs.iterrows():
        movie_id = row['id']
        hybrid_scores[movie_id] = hybrid_scores.get(movie_id, 0) + alpha
    
    for _, row in content_recs.iterrows():
        movie_id = row['id']
        hybrid_scores[movie_id] = hybrid_scores.get(movie_id, 0) + (1 - alpha)
    
    top_ids = sorted(hybrid_scores, key=hybrid_scores.get, reverse=True)[:top_n]
    result = movies_with_clusters[movies_with_clusters['id'].isin(top_ids)][
        ['id', 'title', 'release_year', 'popularity', 'genre_list', 'KÃ¼me']
    ]
    return result

# -------------------------
# 17) Ã–NERÄ°LERÄ° TEST ET
# -------------------------

test_users = [1, 5, 10, 25]

print("\n" + "="*100)
print("ğŸ¯ ADIM 5: Ã–NERÄ° SÄ°STEMÄ°NÄ° TEST EDIYORUZ")
print("="*100)

for user_id in test_users:
    print(f"\n{'='*100}")
    print(f"ğŸ‘¤ KULLANICI {user_id}")
    print(f"{'='*100}")
    
    # Ä°zleme geÃ§miÅŸi
    user_watched = user_behavior_df[user_behavior_df['user_id'] == user_id]
    watched_titles = movies_with_clusters[movies_with_clusters['id'].isin(user_watched['movie_id'])]['title'].tolist()
    
    print(f"\nğŸ“º Bu kullanÄ±cÄ± {len(watched_titles)} film izlemiÅŸ:")
    for i, title in enumerate(watched_titles[:5], 1):
        print(f"   {i}. {title}")
    if len(watched_titles) > 5:
        print(f"   ... ve {len(watched_titles)-5} film daha")
    
    # Ä°ÅŸbirlikÃ§i Ã¶neriler
    print(f"\nğŸ”— YÃ–NTEMÄ° 1: Ä°ÅBÄ°RLÄ°KÃ‡Ä° FÄ°LTRELEME")
    print("   (Benzer zevkteki kullanÄ±cÄ±larÄ±n izlediÄŸi filmler)")
    collab = recommend_movies_collaborative(user_id, top_n=3)
    if not collab.empty:
        for i, (_, row) in enumerate(collab.iterrows(), 1):
            print(f"   {i}. {row['title']} ({int(row['release_year'])}) â­ {row['popularity']:.1f}")
    else:
        print("   âŒ Ã–neri bulunamadÄ±")
    
    # Ä°Ã§erik tabanlÄ± Ã¶neriler
    print(f"\nğŸ“‚ YÃ–NTEMÄ° 2: Ä°Ã‡ERÄ°K TABANLI")
    print("   (AynÄ± tÃ¼rdeki popÃ¼ler filmler)")
    content = recommend_movies_content_based(user_id, top_n=3)
    if not content.empty:
        for i, (_, row) in enumerate(content.iterrows(), 1):
            genres = ", ".join(row['genre_list'][:2])
            print(f"   {i}. {row['title']} ({int(row['release_year'])}) - TÃ¼rler: {genres}")
    else:
        print("   âŒ Ã–neri bulunamadÄ±")
    
    # Hibrit Ã¶neriler
    print(f"\nâš¡ YÃ–NTEMÄ° 3: HÄ°BRÄ°T (Her ikisini birleÅŸtir)")
    hybrid = recommend_movies_hybrid(user_id, top_n=3)
    if not hybrid.empty:
        for i, (_, row) in enumerate(hybrid.iterrows(), 1):
            print(f"   {i}. {row['title']} ({int(row['release_year'])}) â­ {row['popularity']:.1f}")
    else:
        print("   âŒ Ã–neri bulunamadÄ±")

# -------------------------
# 18) SÄ°STEMÄ° KAYDETME
# -------------------------

joblib.dump({
    "user_behavior_df": user_behavior_df,
    "user_item_matrix": user_item_matrix,
    "movies_with_clusters": movies_with_clusters,
    "kmeans": kmeans,
    "scaler": scaler
}, "recommendation_system.joblib")

print("\n\nâœ… Sistem kaydedildi: recommendation_system.joblib")

# -----------------------------------------------
# 19) DETAYLI Ä°STATÄ°STÄ°KSEL ANALÄ°Z
# -----------------------------------------------

print("\n" + "="*100)
print("ğŸ“Š ADIM 6: DETAYLI Ä°STATÄ°STÄ°KLER")
print("="*100)

# Genel istatistikler
print("\nğŸ¬ TÃœJÃœN FÄ°LMLER HAKKINDA:")
print(f"   â€¢ Toplam Film: {len(movies_with_clusters)}")
print(f"   â€¢ Ortalama BÃ¼tÃ§e: ${movies_with_clusters['budget'].mean():,.0f}")
print(f"   â€¢ Ortalama GiÅŸe Geliri: ${movies_with_clusters['revenue'].mean():,.0f}")
print(f"   â€¢ Ortalama PopÃ¼larite PuanÄ±: {movies_with_clusters['popularity'].mean():.2f}/100")
print(f"   â€¢ Ortalama IMDb PuanÄ±: {movies_with_clusters['vote_average'].mean():.2f}/10")
print(f"   â€¢ Ortalama Film SÃ¼resi: {movies_with_clusters['runtime'].mean():.0f} dakika")

# Grup baÅŸÄ±na detaylÄ± istatistikler
print("\n" + "="*100)
print("ğŸ“ˆ HER GRUP (CLUSTER) HAKKINDA DETAYLAR")
print("="*100)

for cl in sorted(movies_with_clusters["KÃ¼me"].dropna().unique()):
    cluster_data = movies_with_clusters[movies_with_clusters["KÃ¼me"] == cl]
    print(f"\n{'â”€'*80}")
    print(f"ğŸ“Œ GRUP {int(cl)} ({len(cluster_data)} film)")
    print(f"{'â”€'*80}")
    print(f"   ğŸ’° BÃ¼tÃ§e:")
    print(f"      â€¢ Minimum: ${cluster_data['budget'].min():,.0f}")
    print(f"      â€¢ Maksimum: ${cluster_data['budget'].max():,.0f}")
    print(f"      â€¢ Ortalama: ${cluster_data['budget'].mean():,.0f}")
    print(f"   ğŸ’µ GiÅŸe Geliri:")
    print(f"      â€¢ Ortalama: ${cluster_data['revenue'].mean():,.0f}")
    print(f"      â€¢ Maksimum: ${cluster_data['revenue'].max():,.0f}")
    print(f"   â­ PopÃ¼larite PuanÄ±: Ort={cluster_data['popularity'].mean():.2f}, Std={cluster_data['popularity'].std():.2f}")
    print(f"   ğŸ“Š IMDb PuanÄ±: {cluster_data['vote_average'].mean():.2f}/10")
    print(f"   ğŸ• Ortalama SÃ¼re: {cluster_data['runtime'].mean():.0f} dakika")

# -----------------------------------------------
# 20) Ã–NERÄ° SÄ°STEMÄ° BAÅARI ORANI
# -----------------------------------------------

print("\n" + "="*100)
print("ğŸ“ˆ Ã–NERÄ° SÄ°STEMÄ° BAÅARI ORANI")
print("="*100)

recommendation_stats = {
    'Ä°ÅŸbirlikÃ§i Filtreleme': {'baÅŸarÄ±': 0, 'toplam': 0},
    'Ä°Ã§erik TabanlÄ±': {'baÅŸarÄ±': 0, 'toplam': 0},
    'Hibrit': {'baÅŸarÄ±': 0, 'toplam': 0}
}

all_test_users = list(user_behavior_df['user_id'].unique())[:20]

for user_id in all_test_users:
    collab = recommend_movies_collaborative(user_id, top_n=5)
    recommendation_stats['Ä°ÅŸbirlikÃ§i Filtreleme']['toplam'] += 1
    if not collab.empty:
        recommendation_stats['Ä°ÅŸbirlikÃ§i Filtreleme']['baÅŸarÄ±'] += 1
    
    content = recommend_movies_content_based(user_id, top_n=5)
    recommendation_stats['Ä°Ã§erik TabanlÄ±']['toplam'] += 1
    if not content.empty:
        recommendation_stats['Ä°Ã§erik TabanlÄ±']['baÅŸarÄ±'] += 1
    
    hybrid = recommend_movies_hybrid(user_id, top_n=5)
    recommendation_stats['Hibrit']['toplam'] += 1
    if not hybrid.empty:
        recommendation_stats['Hibrit']['baÅŸarÄ±'] += 1

print("\nğŸ“Š 20 kullanÄ±cÄ± ile test yapÄ±ldÄ±. SonuÃ§lar:\n")
for method, stats in recommendation_stats.items():
    success_rate = (stats['baÅŸarÄ±'] / stats['toplam'] * 100) if stats['toplam'] > 0 else 0
    print(f"   âœ… {method}: {success_rate:.1f}% baÅŸarÄ± ({stats['baÅŸarÄ±']}/{stats['toplam']})")

# -----------------------------------------------
# 21) GÃ–RSELLEÅTIRMELER
# -----------------------------------------------

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Grup bÃ¼yÃ¼klÃ¼kleri
cluster_sizes = movies_with_clusters['KÃ¼me'].value_counts().sort_index()
axes[0].bar(cluster_sizes.index, cluster_sizes.values, color='skyblue', edgecolor='black')
axes[0].set_title('ğŸ“Š Her Gruptaki Film SayÄ±sÄ±\n(Gruplar deneli daÄŸÄ±lmÄ±ÅŸ mÄ±?)', fontsize=12, fontweight='bold')
axes[0].set_xlabel('Grup NumarasÄ±')
axes[0].set_ylabel('Film SayÄ±sÄ±')
axes[0].grid(True, alpha=0.3, axis='y')

# Grup baÅŸÄ±na ortalama bÃ¼tÃ§e
avg_budget_by_cluster = movies_with_clusters.groupby('KÃ¼me')['budget'].mean()
axes[1].bar(avg_budget_by_cluster.index, avg_budget_by_cluster.values, color='coral', edgecolor='black')
axes[1].set_title('ğŸ’° Her Grubun Ortalama BÃ¼tÃ§esi\n(Hangi gruplar daha pahalÄ±?)', fontsize=12, fontweight='bold')
axes[1].set_xlabel('Grup NumarasÄ±')
axes[1].set_ylabel('Ortalama BÃ¼tÃ§e ($)')
axes[1].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()

# -----------------------------------------------
# 22) FINAL RAPOR
# -----------------------------------------------

print("\n" + "="*100)
print("ğŸ“‹ FÄ°NAL RAPOR - FÄ°LM Ã–NERÄ° SÄ°STEMÄ°")
print("="*100)

report = f"""
ğŸ¯ PROJE NEYÄ° YAPIYOR?
   Filmler otomatik olarak benzer Ã¶zelliklere gÃ¶re gruplara ayrÄ±lÄ±yor.
   KullanÄ±cÄ±lara da benzer zevkindeki kullanÄ±cÄ±larÄ±n izlediÄŸi filmler Ã¶neriliyor.

ğŸ“Š KULLANILAN VERÄ°:
   â€¢ Orijinal KÃ¼tÃ¼phane: {len(movies_full):,} film
   â€¢ Bu Ã‡alÄ±ÅŸtÄ±rmada KullanÄ±lan: {len(movies_with_clusters)} film (rastgele seÃ§ildi)
   â€¢ Ã–zellikler: BÃ¼tÃ§e, PopÃ¼larite, Gelir, SÃ¼re, IMDb PuanÄ±, Oy SayÄ±sÄ±

ğŸ”¬ YAPILAN Ä°ÅLEMLER:
   1ï¸âƒ£  Veri Temizleme: Eksik verileri tamamla, tÃ¼rleri ayÄ±kla
   2ï¸âƒ£  Analiz: Ä°statistikler, korelasyonlar, gÃ¶rseller
   3ï¸âƒ£  KÃ¼meleme: K-Means algoritmasÄ± ile {best_k} grup oluÅŸtur
   4ï¸âƒ£  Ã–neriler: 3 yÃ¶ntemle film Ã¶nerileri ver
   5ï¸âƒ£  DeÄŸerlendirme: BaÅŸarÄ± oranlarÄ±nÄ± Ã¶lÃ§

ğŸ† SONUÃ‡LAR:
   â€¢ SeÃ§ilen grup sayÄ±sÄ±: {best_k} (Silhouette yÃ¶ntemiyle)
   â€¢ SimÃ¼le edilen kullanÄ±cÄ± sayÄ±sÄ±: {user_behavior_df['user_id'].nunique()}
   â€¢ Toplam izleme kaydÄ±: {len(user_behavior_df)}
   â€¢ Hibrit yÃ¶ntem baÅŸarÄ±sÄ±: {recommendation_stats['Hibrit']['baÅŸarÄ±']/recommendation_stats['Hibrit']['toplam']*100:.1f}%

ğŸ’¾ KAYDEDILEN DOSYALAR:
   âœ“ kmeans_pipeline.joblib - KÃ¼meleme modeli
   âœ“ recommendation_system.joblib - Ã–neri sistemi
   âœ“ complete_project.joblib - TÃ¼m veriler
"""

print(report)

# Final kayit
joblib.dump({
    "movies_with_clusters": movies_with_clusters,
    "user_behavior_df": user_behavior_df,
    "user_item_matrix": user_item_matrix,
    "recommendation_stats": recommendation_stats,
    "best_k": best_k,
    "feature_cols": feature_cols
}, "complete_project.joblib")

print("\nâœ… PROJE TAMAMLANDI!")
print("ğŸ’¾ TÃ¼m veriler kaydedildi: complete_project.joblib")
